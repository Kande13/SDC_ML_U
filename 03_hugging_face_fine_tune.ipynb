{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kande13/SDC_ML_U/blob/main/03_hugging_face_fine_tune.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "159978d2",
      "metadata": {
        "id": "159978d2"
      },
      "source": [
        "<img src=\"https://datascientest.fr/train/assets/logo_datascientest.png\" style=\"height:150px\">\n",
        "\n",
        "<hr style=\"border-width:2px;border-color:#75DFC1\">\n",
        "<center><h1 style = \"text-align:center\" > Introduction à Hugging Face </h1></center>\n",
        "<center><h3 style = \"text-align:center\" > Modèle BERT et Fine Tuning </h3></center>\n",
        "<hr style=\"border-width:2px;border-color:#75DFC1\">\n",
        "\n",
        "> Maintenant que le rappel sur PyTorch a été fait, adaptons et entraînons un modèle d'Hugging Face pour la classification de sentiments. Mais, avant ça, un petit rappel sur les transformers et une présentation du modèle BERT et CamemBERT.\n",
        "\n",
        "\n",
        "## Rappel sur les Transformers\n",
        "\n",
        "> Les premiers Transformers ont été développés par Google et publiés dans le célèbre papier de recherche [Attention is all you need](https://arxiv.org/abs/1706.03762).\n",
        ">\n",
        "> Comme pour les RNN, le Transformer est adapté au traitement de données séquentielles. Avant la sortie du Transformer, l'état de l'art de beaucoup de tâches comme la traduction était détenu par des RNNs avec des mécanismes d'attention.\n",
        ">\n",
        "> La force des RNNs est qu'ils fonctionnent de manière similaire aux MLPs mais sont capables de comprendre l'importance de l'ordre des mots dans une phrase. En effet, les mots sont encodés un par un à travers le réseau en laissant une trace dans les états cachés du réseau. Ainsi, l'ordre des mots va grandement impacter l'encodage d'une phrase.\n",
        ">\n",
        "> Quant au Transformer, il n'utilise que des `dense` layers et des mécanismes d'attention pour encoder/décoder une séquence, ce qui rend les calculs beaucoup plus parallélisable comparés au RNN. Il encode tous les mots simultanément en parallèle.\n",
        ">\n",
        "> Voici le schéma de l'architecture entière telle que présentée dans le papier ***Attention is all you need*** :\n",
        ">\n",
        "> <br>\n",
        ">\n",
        "> <img src = \"https://assets-datascientest.s3-eu-west-1.amazonaws.com/train/Transformer_full.png\" style = \"width:800px\">\n",
        ">\n",
        "> Comme le mécanismes d'attention n'est pas capable naïvement de comprendre l'ordre des mots dans la phrase, les auteurs du papier *Attention is all you need* ont proposé une solution pour encoder la position d'un mot dans une phrase directement dans son vecteur d'Embedding.\n",
        "\n",
        "\n",
        "## Structure des Transformers\n",
        "\n",
        "> Selon l'utilisation, il n'est pas toujours nécessaire d'utiliser un encodeur ou un décodeur. En effet, dans le cas de la classification de texte, il n'est pas nécessaire d'avoir un décodeur. Un simple encodeur avec une tête de classification est suffisant. Alors que dans des tâches nécessitant une génération, il sera nécessaire d'avoir au moins un décodeur.\n",
        ">\n",
        ">\n",
        "> Dans les modèles avec uniquement un **encodeur**, comme les modèles BERT, RoBERTa, CammemBERT, FlauBERT, ils pourront être utilisés pour des tâches comme la classification de texte (analyse de sentiment, détection de langue, type de documents...), des tâches de classification de tokens (NER, POS Tagging...) et bien d'autres.\n",
        ">\n",
        ">\n",
        "> Dans les modèles avec uniquement un **décodeur**, comme le GPT, ils sont utilisés initialement dans la génération de texte, mais, adaptable à n'importe quelle problématique de NLP. Il sera cependant nécessaire d'adapter la sortie du modèle pour son entraînement ou son utilisation.\n",
        ">\n",
        ">\n",
        "> Enfin, des modèles avec un **encodeur** et un **décodeur**, comme le T5, sont généralement utilisés dans le cas où il est nécessaire d'encoder une donnée d'entrée pour générer une sortie (par exemple, encoder dans le langage source pour le générer dans le langage cible).\n",
        "\n",
        "\n",
        "\n",
        "<hr style=\"border-width:2px;border-color:#75DFC1\">\n",
        "<center><h3 style = \"text-align:center\" > Modèle BERT </h3></center>\n",
        "<hr style=\"border-width:2px;border-color:#75DFC1\">\n",
        "\n",
        "> Le modèle BERT (Bidirectional Encoder Representations from Transformers) est un modèle de traitement du langage naturel (NLP) développé par Google. Il s'agit d'un modèle avec uniquement un encodeur sur le transformer.\n",
        ">\n",
        "> Le modèle BERT est d'abord pré-entraîné sur de vastes quantités de données textuelles, telles que des livres, des articles et des pages Web. Au cours de ce pré-entraînement, BERT apprend au travers de problématique non-supervisées (prédire des mots masqués...) à capturer plus facilement la sémantique du langage (sens des mots, contexte, subtilité), mais apporte également au modèle une connaissance générale.\n",
        ">\n",
        "> Après l'entraînement, le modèle BERT peut être utilisé dans une grande variété de tâches de NLP, peut être réentraîner sur des tâches spécifiques, telles que la classification de texte, la détection d'entités nommées, la compréhension des intentions des utilisateurs, etc. (sur toutes problématiques où le modèle n'a pas besoin d'un décodeur).\n",
        ">\n",
        "> Détaillons maintenant un peu plus la phase de pré-entraînement et de Fine Tuning du modèle.\n",
        ">\n",
        "><img src=\"https://assets-datascientest.s3-eu-west-1.amazonaws.com/notebooks/hugging_face_bert.jpg\">\n",
        ">\n",
        "><center><b>Source : </b> Provenant du <a href=https://arxiv.org/abs/1810.04805>papier de recherche BERT</a></center>\n",
        "\n",
        "## Pré-entraînement\n",
        "\n",
        "> En effet, les modèles Transformers, de manière générale, ont d'excellentes propriétés de \"transfer learning\", et sans cette étape, les modèles ne surpasseraient guère les approches plus traditionnelles comme les BoW, TFIDF... Comme dans l'entraînement des Word Embeddings, il est généralement préférable en NLP de pré-entraîner les modèles sur une tâche nécessitant du texte, et par conséquent sur un entraînement non supervisé.\n",
        ">\n",
        "> <div class=\"alert alert-info\"><i class=\"fa fa-info-circle\"></i> &emsp;\n",
        "Pré-entraîner le modèle sur des tâches supervisées (sentiment analysis...) risque de complètement biaiser les embeddings, et le modèle risque de ne capturer que les informations en rapport avec la tâche (par exemple, le sentiment des mots, mais pas le sens en lui-même).</div>\n",
        ">\n",
        ">\n",
        "> Ce pré-entraînement permet au modèle de capturer la sémantique du langage (sens des mots, subtilité du langage, contexte, sarcasme et bien plus), mais aussi un transfert de connaissances du domaine des documents sur lequel le modèle est entraîné.\n",
        ">\n",
        "> Dans cette phase, le modèle est entraîné sur un jeu de données [BooksCorpus](https://huggingface.co/datasets/bookcorpus) (800M mots) contenant environ 11k livres et [English Wikipedia](https://huggingface.co/datasets/wikipedia/viewer/20220301.en/train) (2,500M mots), en ignorant les listes, tableaux et en-têtes.\n",
        ">\n",
        ">  Il utilise deux tâches de pré-entraînement principales: \"Masked Language Modeling\" (MLM) et \"Next Sentence Prediction\" (NSP).\n",
        ">\n",
        ">\n",
        ">\n",
        "> * **Next Sentence Prediction** (NSP) : Dans cette tâche, le modèle reçoit deux phrases et doit prédire si la deuxième phrase est la suite logique de la première. La tâche aide le modèle BERT à comprendre la relation entre les phrases, ce qui est une information structurelle plus large que celle que l'on peut obtenir en regardant simplement les mots individuels. D'après le papier de recherche, cela a permis des améliorations pour des tâches comme le \"Question Answering\" (QA) ou le \"Natural Language Inference\" (NLI), puisqu'ils nécessitent de bien comprendre les relations entre plusieurs phrases.\n",
        ">\n",
        ">\n",
        "> <img src=\"https://assets-datascientest.s3-eu-west-1.amazonaws.com/notebooks/hugging_face_bert_snp.png\">\n",
        ">\n",
        ">\n",
        "> <div class=\"alert alert-info\">\n",
        "><i class=\"fa fa-info-circle\"></i> &emsp;\n",
        "Plus précisément, lors du choix des phrases A et B, 50 % du temps, B est la phrase qui suit A, et sinon, c'est une phrase aléatoire prise dans le corpus.\n",
        "></div>\n",
        ">\n",
        ">\n",
        ">\n",
        "> * **Masked Language Modeling** (MLM) : Dans cette tâche, environ **15% des mots** de la phrase sont masqués (remplacé par un token \"[mask]\"), et le modèle est alors entraîné à prédire ces mots masqués en se basant sur le contexte de la phrase. Le MLM aide le modèle à comprendre le contexte dans lequel un mot est utilisé. En d'autres termes, il aide le modèle à apprendre que le sens d'un mot peut changer en fonction des mots qui l'entourent. Par exemple, le mot \"canard\" peut désigner un animal ou une action d'évitement, selon le contexte.\n",
        ">\n",
        ">\n",
        "> <img src=\"https://assets-datascientest.s3-eu-west-1.amazonaws.com/notebooks/hugging_face_bert_mask.png\">\n",
        ">\n",
        ">\n",
        "> <div class=\"alert alert-info\">\n",
        "><i class=\"fa fa-info-circle\"></i> &emsp;\n",
        "Les concepteurs de BERT ont décidé d'introduire un certain niveau de bruit dans le processus pour aider le modèle à mieux généraliser. Plus précisément, pour chaque mot qui est sélectionné pour être masqué :<ul>\n",
        "    <li>80% du temps, le mot est remplacé par le token masque \"[MASK]\".</li>\n",
        "    <li>10% du temps, le mot est remplacé par un autre mot aléatoire.</li>\n",
        "    <li>10% du temps, le mot n'est pas changé du tout.</li>\n",
        "></ul>\n",
        "></div>\n",
        ">\n",
        ">\n",
        "> En choisissant ces deux tâches de pré-entraînement, les concepteurs de BERT visent à créer un modèle qui comprend à la fois le contexte des mots au niveau de la phrase et la structure des textes à un niveau plus large. De plus, ces deux tâches peuvent être effectuées en utilisant des données non étiquetées à grande échelle, ce qui est un avantage important pour le pré-entraînement de modèles de langage qui doivent comprendre une grande variété de textes.\n",
        "\n",
        "\n",
        "\n",
        "## Fine Tuning\n",
        "\n",
        ">\n",
        ">\n",
        "> Une fois le modèle BERT pré-entraîné, il suffit en suite d'adapter la structure à la tâche souhaitée puis de réentraîner le modèle. Par exemple, dans le cas de la classification de documents, une couche \"Dense\" est appliquée sur l'embedding du premier token ([CLS]) :\n",
        ">\n",
        ">\n",
        "> <img src=\"https://assets-datascientest.s3-eu-west-1.amazonaws.com/notebooks/hugging_face_bert_classification.png\">\n",
        ">\n",
        "> <div class=\"alert alert-info\"><i class=\"fa fa-info-circle\"></i> &emsp;\n",
        "Il est intéressant de noter que tous les paramètres sont entraînés avec un learning rate très bas lors de la phase de fine tuning du modèle.  </div>\n",
        ">\n",
        ">\n",
        "> Mais, il est tout à fait possible d'adapter la structure sur d'autres tâches comme la sentence pair classification (similairité entre deux phrases par exemple), la reconnaissance d'entitée nommée (NER), la détéction de la nature grammaticale (POS Tagging), question answering (trouver les tokens dans le contexte qui réponde à la question) et bien d'autres applications.\n",
        ">\n",
        ">\n",
        "> <img src=\"https://assets-datascientest.s3-eu-west-1.amazonaws.com/notebooks/hugging_face_bert_tasks.png\">\n",
        "\n",
        "\n",
        "## Variante du modèle BERT\n",
        "\n",
        "> Depuis l'adoption du modèle BERT, de nombreuses variantes et améliorations ont été introduites. Quelques exemples :\n",
        ">\n",
        ">\n",
        ">* [RoBERTa](https://arxiv.org/abs/1907.11692) (Robustly Optimized BERT Approach) : une version de BERT optimisée par Facebook, avec plus de paramètres et des séquences plus longues lors d'entraînement, beaucoup plus de données (BookCorpus/wikipedia anglais (16GB), CC-News (76GB), OpenWebText (38GB) et Stories (31GB)), sans la tâche NSP, préentraînement uniqument avec un masquage dynamique.\n",
        ">\n",
        "> <div class=\"alert alert-info\"><i class=\"fa fa-info-circle\"></i> &emsp;\n",
        "L'implémentation du BERT original utilise un masque dit statique, en effet, leur masquage a été fait lors du prétraitement des données, ce qui a donné un seul masque statique par donnée (la donnée aura toujours le même masquage). Pour avoir plus de variété, ils ont fait passer 10 fois chaque texte afin que chaque séquence soit masquée de 10 manières différentes.\n",
        "Alors que dans le cas masquage dynamique, c'est appliqué au moment d'alimenter le modèle. </div>\n",
        ">\n",
        ">\n",
        "> * [DistilBERT](https://arxiv.org/abs/1910.01108): une version réduite de BERT introduite par Hugging Face qui est environ 40% plus petite et 60% plus rapide, tout en conservant 95% des performances de BERT. Lors du pré-entraînement, le modèle DistilBERT recherche à copier la prédiction du modèle BERT sur la tâche de prédiction des mots . Pour cela, les auteurs utilisent trois fonctions de pertes :\n",
        ">\n",
        ">> * Une fonction de **perte de distallation**, qui recherchera à faire que le modèle prédise la même distribution de probabilité que le modèle BERT.\n",
        ">>\n",
        ">> $$ L{ce} = \\sum_i^C t_i * \\log(s_i)$$ avec C le nombre de classe, $t_i$ la probabilité du modèle bert et $s_i$ la probabilité du distilBERT.\n",
        ">>\n",
        ">> <div class=\"alert alert-info\"><i class=\"fa fa-info-circle\"></i> &emsp;\n",
        "Pour éviter d'avoir une distribution de probabilité trop inégale (trop forte probabilité sur la classe cible), ils appliquent une \"softmax-temperature\"  $p_i = \\frac{exp(z_i/T)}{\\sum_jexp(z_j/T)}$ sur les deux modèles. </div>\n",
        ">>\n",
        ">> * Une fonction de perte **cross-entropy** entre la **vraie target** et la **prédiction du distilBERT** ($L{mlm}$) sur la tâche de \"masked language modeling\" (MLM) $ L{mlm} = -\\log(s)$ avec $s$ la probabilité du modèle distilBERT sur la classe cible.\n",
        ">>\n",
        ">>\n",
        ">> * Une fonction de perte de **[cosine embedding](https://pytorch.org/docs/stable/generated/torch.nn.CosineEmbeddingLoss.html)** entre les embeddings du distilBERT et du modèle BERT pour aligner les directions des embeddings entre les deux modèles. Ici, la définition pour chaque état de la séquence : $L{cos} = 1 - \\cos(S_{BERT}, S_{distilBERT})$\n",
        ">>\n",
        ">>\n",
        ">> <img src='https://assets-datascientest.s3-eu-west-1.amazonaws.com/notebooks/hugging_face_distilbert.png'>\n",
        ">>\n",
        ">>\n",
        ">><center><i><b>Figure :</b> Présentation de la fonction de perte sur le 3ème token</i></center>\n",
        ">\n",
        "> * [CamemBERT](https://arxiv.org/abs/1911.03894): c'est une variante de RoBERTa adaptée à la langue française.\n",
        "\n",
        "<hr style=\"border-width:2px;border-color:#75DFC1\">\n",
        "<center><h2 style = \"text-align:center\" > Application </h2></center>\n",
        "<hr style=\"border-width:2px;border-color:#75DFC1\">\n",
        "\n",
        "> La sélection d'un modèle pourra se faire essentiellement sur deux grands critères :\n",
        ">\n",
        "> * le **temps d'inférence**: souvent relié au nombre de paramètres du modèle.\n",
        ">\n",
        ">\n",
        "> * la **performance du modèle** sur sa tâche de base ou sur des benchmarks: une référence en anglais peut être [GLUE](https://gluebenchmark.com/leaderboard), ou en français [FLUE](http://fluebenchmark.com/).\n",
        ">\n",
        ">\n",
        "> Il est aussi possible de trouver des spaces sur Hugging Face qui contiennent des leaderboards:\n",
        "> * **Leaderboard pour du text embedding**: https://huggingface.co/spaces/mteb/leaderboard\n",
        ">\n",
        "> * **Leaderboard pour des LLMs**: https://huggingface.co/spaces/lmarena-ai/chatbot-arena-leaderboard\n",
        ">\n",
        ">\n",
        "> Ici, nous allons nous orienter vers le modèle FlauBERT, qui est une variante du RoBERTa adaptée à la langue française, sorti un peu après le modèle CamemBERT. Il existe deux variantes \"Base\" ou \"Large\" possédant globalement plus de paramètres que le CamemBERT.\n",
        ">\n",
        ">\n",
        "><img src=\"https://assets-datascientest.s3-eu-west-1.amazonaws.com/notebooks/hugging_face_bert_flaubert_datasets.png\">\n",
        ">\n",
        ">\n",
        "> Ce modèle propose généralement des résultats un peu meilleurs que le modèle CamemBERT, surtout dans sa forme \"Large\".\n",
        "\n",
        "## Chargement des données et préparation\n",
        "\n",
        "* Charger dans un dataframe **`df`** le jeu de données https://assets-datascientest.s3.eu-west-1.amazonaws.com/datasets/nlp/insurrance-cleaned.csv.\n",
        "\n",
        "\n",
        "* Faire un bref audit dessus."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "RJZZoCOKRh17",
      "metadata": {
        "id": "RJZZoCOKRh17"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U acceleration\n",
        "!pip install -q sacremoses\n",
        "!pip install -q evaluator\n",
        "#restart the kernel\n",
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d3e86e9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 681
        },
        "id": "9d3e86e9",
        "outputId": "c6a658c3-36a5-49d5-c0bd-08c57fe8ffdf",
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Commentaire</th>\n",
              "      <th>day</th>\n",
              "      <th>Mois</th>\n",
              "      <th>year</th>\n",
              "      <th>Note</th>\n",
              "      <th>Assureur</th>\n",
              "      <th>Produit</th>\n",
              "      <th>month</th>\n",
              "      <th>date</th>\n",
              "      <th>Langue</th>\n",
              "      <th>...</th>\n",
              "      <th>chain_capslock</th>\n",
              "      <th>exclamations</th>\n",
              "      <th>chain_exclamation</th>\n",
              "      <th>interogation</th>\n",
              "      <th>chain_interogation</th>\n",
              "      <th>etc</th>\n",
              "      <th>nb_caracter</th>\n",
              "      <th>nb_words</th>\n",
              "      <th>nb_sentences</th>\n",
              "      <th>cleaned</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>37923</th>\n",
              "      <td>Satisfaction mitigé. Sur le papier c'est bien</td>\n",
              "      <td>20</td>\n",
              "      <td>juin</td>\n",
              "      <td>2013</td>\n",
              "      <td>1.5</td>\n",
              "      <td>DIRECT-ASSURANCE</td>\n",
              "      <td>Assurance-Auto</td>\n",
              "      <td>6</td>\n",
              "      <td>2013-06-20 18:48:00</td>\n",
              "      <td>__label__fr</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>45</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>satisfaction mitiger . papier bien</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20877</th>\n",
              "      <td>Je suis vraiment satisfaite. Merci de tant vei...</td>\n",
              "      <td>9</td>\n",
              "      <td>août</td>\n",
              "      <td>2021</td>\n",
              "      <td>3.5</td>\n",
              "      <td>SOGESSUR</td>\n",
              "      <td>Autres-Produits</td>\n",
              "      <td>8</td>\n",
              "      <td>2021-08-09</td>\n",
              "      <td>__label__fr</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>159</td>\n",
              "      <td>22</td>\n",
              "      <td>2</td>\n",
              "      <td>vraiment satisfaire . veiller client particuli...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56364</th>\n",
              "      <td>Tarif tres conpétitif aucun probléme pour assu...</td>\n",
              "      <td>12</td>\n",
              "      <td>février</td>\n",
              "      <td>2009</td>\n",
              "      <td>5.0</td>\n",
              "      <td>MACIF</td>\n",
              "      <td>Assurance-Auto</td>\n",
              "      <td>2</td>\n",
              "      <td>2009-02-12 20:15:00</td>\n",
              "      <td>__label__fr</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>269</td>\n",
              "      <td>47</td>\n",
              "      <td>0</td>\n",
              "      <td>tarif . conpétitif aucun probléme assurer type...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35806</th>\n",
              "      <td>Plus d'1 mois de traitement du dossier, interl...</td>\n",
              "      <td>16</td>\n",
              "      <td>avril</td>\n",
              "      <td>2015</td>\n",
              "      <td>2.0</td>\n",
              "      <td>APRIL</td>\n",
              "      <td>Assurance-Habitation</td>\n",
              "      <td>4</td>\n",
              "      <td>2015-04-16 08:13:00</td>\n",
              "      <td>__label__fr</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>121</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>d'1 mois traitement dossier interlocuteur comm...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30399</th>\n",
              "      <td>Viré de la Matmut après deux sinistres respons...</td>\n",
              "      <td>22</td>\n",
              "      <td>novembre</td>\n",
              "      <td>2020</td>\n",
              "      <td>2.0</td>\n",
              "      <td>MATMUT</td>\n",
              "      <td>Assurance-Habitation</td>\n",
              "      <td>11</td>\n",
              "      <td>2020-11-22</td>\n",
              "      <td>__label__fr</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>178</td>\n",
              "      <td>31</td>\n",
              "      <td>3</td>\n",
              "      <td>virer matmut sinistre responsable 35 an . \\n m...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 26 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             Commentaire  day      Mois  year   \n",
              "37923      Satisfaction mitigé. Sur le papier c'est bien   20      juin  2013  \\\n",
              "20877  Je suis vraiment satisfaite. Merci de tant vei...    9      août  2021   \n",
              "56364  Tarif tres conpétitif aucun probléme pour assu...   12   février  2009   \n",
              "35806  Plus d'1 mois de traitement du dossier, interl...   16     avril  2015   \n",
              "30399  Viré de la Matmut après deux sinistres respons...   22  novembre  2020   \n",
              "\n",
              "       Note          Assureur               Produit  month   \n",
              "37923   1.5  DIRECT-ASSURANCE        Assurance-Auto      6  \\\n",
              "20877   3.5          SOGESSUR       Autres-Produits      8   \n",
              "56364   5.0             MACIF        Assurance-Auto      2   \n",
              "35806   2.0             APRIL  Assurance-Habitation      4   \n",
              "30399   2.0            MATMUT  Assurance-Habitation     11   \n",
              "\n",
              "                      date       Langue  ...  chain_capslock  exclamations   \n",
              "37923  2013-06-20 18:48:00  __label__fr  ...               0             0  \\\n",
              "20877           2021-08-09  __label__fr  ...               0             0   \n",
              "56364  2009-02-12 20:15:00  __label__fr  ...               0             0   \n",
              "35806  2015-04-16 08:13:00  __label__fr  ...               0             0   \n",
              "30399           2020-11-22  __label__fr  ...               0             0   \n",
              "\n",
              "       chain_exclamation  interogation  chain_interogation  etc  nb_caracter   \n",
              "37923                  0             0                   0    0           45  \\\n",
              "20877                  0             0                   0    0          159   \n",
              "56364                  0             0                   0    0          269   \n",
              "35806                  0             0                   0    1          121   \n",
              "30399                  0             0                   0    0          178   \n",
              "\n",
              "       nb_words  nb_sentences   \n",
              "37923         7             1  \\\n",
              "20877        22             2   \n",
              "56364        47             0   \n",
              "35806        20             0   \n",
              "30399        31             3   \n",
              "\n",
              "                                                 cleaned  \n",
              "37923                 satisfaction mitiger . papier bien  \n",
              "20877  vraiment satisfaire . veiller client particuli...  \n",
              "56364  tarif . conpétitif aucun probléme assurer type...  \n",
              "35806  d'1 mois traitement dossier interlocuteur comm...  \n",
              "30399  virer matmut sinistre responsable 35 an . \\n m...  \n",
              "\n",
              "[5 rows x 26 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('https://assets-datascientest.s3.eu-west-1.amazonaws.com/datasets/nlp/insurrance-cleaned.csv', index_col=0)\n",
        "df = df.sample(1000)\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab967f58",
      "metadata": {
        "id": "ab967f58"
      },
      "source": [
        "> Dans cette implémentation, nous allons rechercher à prédire si le commentaire est positif ou non. On considérera qu'un commentaire est négatif si sa note est inférieure ou égale à 2.5.\n",
        "\n",
        "* Ajouter une colonne sous le nom **`target`** qui indique si le commentaire est négatif (0) ou positif (1).\n",
        "\n",
        "\n",
        "* Afficher la répartition."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7cc6a1a5",
      "metadata": {
        "id": "7cc6a1a5",
        "outputId": "5e10a8f5-b1f6-4543-e209-23e3edbe6877"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<AxesSubplot: ylabel='count'>"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "df[\"target\"] =  df['Note'].apply(lambda x : 1 if x>2.5 else 0)\n",
        "df.target.value_counts().plot.pie()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c04bcd9",
      "metadata": {
        "id": "3c04bcd9"
      },
      "source": [
        "* Exécuter la cellule suivante pour séparer les données."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2defee9",
      "metadata": {
        "id": "d2defee9"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df['Commentaire'].values,\n",
        "    df['target'].values,\n",
        "    test_size=0.2,\n",
        "    random_state=123,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e298d371",
      "metadata": {
        "id": "e298d371"
      },
      "source": [
        "* Charger le tokenizer \"flaubert/flaubert_base_cased\" sous le nom **`tokenizer`**.\n",
        "\n",
        "\n",
        "* Appliquer la méthode **`tokenize`** au texte \"Les étudiants sèchent quand il fait beau\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d33edb2",
      "metadata": {
        "id": "5d33edb2",
        "outputId": "df613c1e-e855-472a-849e-551852c54340"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Les</w>',\n",
              " 'étudiants</w>',\n",
              " 'sè',\n",
              " 'chent</w>',\n",
              " 'quand</w>',\n",
              " 'il</w>',\n",
              " 'fait</w>',\n",
              " 'beau</w>']"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"flaubert/flaubert_base_cased\")\n",
        "\n",
        "## Equivalent\n",
        "# from transformers import FlaubertModel, FlaubertTokenizer\n",
        "# tokenizer = FlaubertTokenizer.from_pretrained(\"flaubert/flaubert_base_cased\")\n",
        "\n",
        "tokenizer.tokenize(\"Les étudiants sèchent quand il fait beau\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "feb8d863",
      "metadata": {
        "id": "feb8d863"
      },
      "source": [
        "> Il est intéressant de remarquer dans le résultat plus haut que le tokenizer n'est pas à l'échelle du mot, mais à une échelle plus petite. En effet, ce tokenizer trouve le bon compromis entre dimension et sens. Un tokenizer à l'échelle du mot risque d'exploser en dimension à cause de la variété des formes qu'un mot peut avoir (par exemple, \"manger\", \"mangé\", \"mangeant\"). Alors qu'un tokenizer à l'échelle du caractère cause des longueurs de séquence trop grande et qu'une simple lettre peut changer le sens d'un mot (par exemple, \"hat\" et \"hate\").\n",
        ">\n",
        "> Les modèles RoBertA ou FlauBERT et bien d'autres utilisent l'approche de tokenisation \"[Byte Pair Encoding](https://arxiv.org/abs/1508.07909)\" (BPE). Ils résolvent ces problèmes en tokenisant à un niveau sublexical (partie d'un mot). L'idée est d'identifier les paires de bytes (ou caractères) les plus fréquentes dans le corpus de texte et de les traiter comme une seule unité. Par exemple, le mot \"chat\" pourrait être divisé en \"c\", \"h\", \"a\", \"t\" au début, mais si \"ch\" est une paire fréquente, elle serait traitée comme une seule unité \"ch\" à l'avenir.\n",
        ">\n",
        ">\n",
        "> Voici un exemple de comment BPE fonctionne en pratique :\n",
        ">\n",
        ">0. Compter l'occurence de chaque mot du vocabulaire provenant du jeu d'entraînement.\n",
        ">\n",
        ">\n",
        ">```python\n",
        ">(\"hug\", 10), (\"pug\", 5), (\"pun\", 12), (\"bun\", 4), (\"hugs\", 5)\n",
        ">```\n",
        ">\n",
        ">\n",
        ">1. Initialisation : Chaque mot est d'abord divisé en caractères individuels\n",
        ">```\n",
        ">(\"h\" \"u\" \"g\", 10), (\"p\" \"u\" \"g\", 5), (\"p\" \"u\" \"n\", 12), (\"b\" \"u\" \"n\", 4), (\"h\" \"u\" \"g\" \"s\", 5)\n",
        ">```\n",
        ">\n",
        ">> On petit ici initialiser notre vocabulaire de base à:\n",
        ">>\n",
        ">>```python\n",
        ">>voc_base = [\"b\", \"g\", \"h\", \"n\", \"p\", \"s\", \"u\"]\n",
        ">>```\n",
        ">\n",
        ">\n",
        ">2. Fréquence des paires : On identifie la paire de caractères consécutifs la plus fréquente dans le corpus. Par exemple, ici, la paire \"ug\" apparaît 20 fois.\n",
        ">```\n",
        "(\"h\" \"ug\", 10), (\"p\" \"ug\", 5), (\"p\" \"u\" \"n\", 12), (\"b\" \"u\" \"n\", 4), (\"h\" \"ug\" \"s\", 5)\n",
        ">```\n",
        ">\n",
        ">3. On fusionne \"u\" et \"g\", puis on met à jour le vocabulaire de base\n",
        ">\n",
        ">```python\n",
        ">voc_base = [\"b\", \"g\", \"h\", \"n\", \"p\", \"s\", \"u\", \"ug\"]\n",
        ">```\n",
        ">\n",
        ">4. Répétez les étapes 2 et 3 autant de fois que vous le souhaitez, en créant de plus en plus de symboles composés.\n",
        ">\n",
        ">\n",
        ">Au fil du temps, cela permet de créer un vocabulaire de sous-mots, où chaque \"mot\" est soit un caractère unique, soit une chaîne de caractères qui apparaissent fréquemment ensemble. Ce vocabulaire peut ensuite être utilisé pour tokeniser de nouveaux textes.\n",
        "\n",
        "## Définition du générateur\n",
        "\n",
        "\n",
        "> Maintenant que le tokenizer a été chargé, préparons les données pour le modèle.\n",
        ">\n",
        ">\n",
        "> Comme présenté dans l'exercice précédent, il existe plusieurs approches pour préparer les données et les séparer en lot. Si il y'a un besoin de flexibilité, l'approche par générateur personnalisé est préférable. Il sera en suite nécessaire de le combiner avec un `DataLoader` pour créer des lots de données.\n",
        ">\n",
        ">```python\n",
        ">import torch\n",
        ">from torch.utils.data import DataLoader\n",
        ">\n",
        ">class NewsGroupsDataset(torch.utils.data.Dataset):\n",
        ">     def __init__(self, X, y, device=\"cpu\", max_length=256):\n",
        ">         self.X = X\n",
        ">         self.y = y\n",
        ">         self.max_length = max_length\n",
        ">         self.device = device\n",
        ">\n",
        ">     def __getitem__(self, idx):\n",
        ">         text = self.X[idx]\n",
        ">         # Transformation des données\n",
        ">         encoding = tokenizer(text,\n",
        ">                             truncation=True,        # Couper le texte jusqu'au max_length\n",
        ">                             padding='max_length',   # Faire du padding jusqu'au max_length\n",
        ">                             max_length=self.max_length,         # Taille maximale des tokens\n",
        ">                             return_tensors=\"pt\")    # Format renvoyé après tokenization ('pt' == pytorch)\n",
        ">         \n",
        ">\n",
        ">         return {'input_ids':encoding['input_ids'][0].to(self.device),\n",
        ">                 'token_type_ids':encoding['token_type_ids'][0].to(self.device),\n",
        ">                 'attention_mask':encoding['attention_mask'][0].to(self.device) ,\n",
        ">                 'labels':torch.tensor(self.y[idx]).to(self.device)}\n",
        ">\n",
        ">\n",
        ">     def __len__(self):\n",
        ">         return len(self.X)\n",
        ">\n",
        ">\n",
        ">train_set = NewsGroupsDataset(X_train, y_train)\n",
        ">train_loader = DataLoader(train_set, batch_size=4, shuffle=True)\n",
        ">```\n",
        ">\n",
        "><br></br>\n",
        ">*  Ou, si la donnée est déjà chargée :\n",
        ">\n",
        ">```python\n",
        "># Transformer tous les textes en format d'entrée du modèle.\n",
        "> encoded_data_train = tokenizer.batch_encode_plus(\n",
        "    X_train, # Liste de texte\n",
        "    add_special_tokens=True, # Ajouter un token spécial lors de la tokenization [CLS]...\n",
        "    return_attention_mask=True, # Retourne pour chaque token si c'est un mot ou un token padding\n",
        "    truncation=True, # Couper les textes jusqu'au max_length\n",
        "    padding='max_length',   # Faire du padding jusqu'a la max_length\n",
        "    max_length=max_length, # Taille maximale des tokens\n",
        "    return_tensors=\"pt\", # Format renvoyé après tokenization ('pt' == tenseur)\n",
        ")\n",
        ">train_set = TensorDataset(encoded_data_train[\"input_ids\"], encoded_data_train[\"attention_mask\"], torch.tensor(y_train))\n",
        "># Regrouper sous forme de lot de données.\n",
        ">train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
        ">```\n",
        ">\n",
        "> Vous trouver l'implémentation par `TensorDataset` au travers de ce colab : https://colab.research.google.com/drive/1hR8Og0umoC9O6d7NATg-iwowNbHJHSCH?usp=sharing\n",
        "\n",
        "\n",
        "* Définir un générateur personnalisé adapté à votre problématique.\n",
        "\n",
        "\n",
        "* Définir une instance du générateur sous le nom **`dataset_train`** de `X_train`, `y_train`.\n",
        "\n",
        "\n",
        "* Faire de même sur le jeu de données test. Stocker le résultat sous le nom **`dataset_test`**.\n",
        "\n",
        "\n",
        "* Afficher le résultat d'une itération du générateur `next(iter(dataset_train))`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a55e173",
      "metadata": {
        "id": "0a55e173"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "batch_size = 4\n",
        "\n",
        "class NewsGroupsDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, X, y, device=\"cuda\", max_length=256):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.max_length = max_length\n",
        "        self.device = device\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Transformation des données\n",
        "        encoding = tokenizer(self.X[idx],\n",
        "                            truncation=True,        # Couper le texte jusqu'au max_length\n",
        "                            padding='max_length',   # Faire du padding jusqu'au max_length\n",
        "                            max_length=self.max_length,         # Taille maximale des tokens\n",
        "                            return_tensors=\"pt\")    # Format renvoyé après tokenization ('pt' == pytorch)\n",
        "\n",
        "\n",
        "        return {'input_ids':encoding['input_ids'][0].to(self.device),\n",
        "                'token_type_ids':encoding['token_type_ids'][0].to(self.device),\n",
        "                'attention_mask':encoding['attention_mask'][0].to(self.device) ,\n",
        "                'labels':torch.tensor(self.y[idx]).to(self.device)}\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "\n",
        "dataset_train = NewsGroupsDataset(X_train, y_train)\n",
        "dataset_test = NewsGroupsDataset(X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6e021b0",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "c6e021b0",
        "run_control": {
          "frozen": true
        }
      },
      "source": [
        "* Définir un `DataLoader` pour le générateur d'entraînement pour regrouper nos observation en batch. Nommer le **`dataloader_train`**.\n",
        "\n",
        "\n",
        "* Définir un `DataLoader` pour le générateur de test pour regrouper nos observation en batch. Nommer le **`dataloader_test`**.\n",
        "\n",
        "\n",
        "* Stocker dans **`X_t`** le résultat d'une itération du générateur `next(iter(dataloader_train))` et l'afficher."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79d4d7ae",
      "metadata": {
        "id": "79d4d7ae",
        "outputId": "1f61d709-7ff3-4a22-93d7-270ca6aa2097"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[  0, 107, 176,  ...,   2,   2,   2],\n",
              "         [  0,  22, 237,  ...,   2,   2,   2],\n",
              "         [  0, 107, 176,  ...,   2,   2,   2],\n",
              "         [  0, 243, 387,  ...,   2,   2,   2]], device='cuda:0'),\n",
              " 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0'),\n",
              " 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 0, 0, 0],\n",
              "         [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0'),\n",
              " 'labels': tensor([1, 1, 1, 1], device='cuda:0')}"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataloader_train = DataLoader(\n",
        "    dataset_train, shuffle=True, batch_size=batch_size\n",
        ")\n",
        "\n",
        "dataloader_test = DataLoader(\n",
        "    dataset_test, batch_size=batch_size)\n",
        "\n",
        "\n",
        "X_t = next(iter(dataloader_train))\n",
        "X_t"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c61a53ee",
      "metadata": {
        "id": "c61a53ee"
      },
      "source": [
        "## Chargement du modèle\n",
        "\n",
        "> Pour charger le modèle, il suffit de se rendre sur la page du modèle, et de récupérer le code associé. Il est également possible de spécifier l'argument `num_labels` qui remplacera la dernière couche du modèle par une adaptée à votre problématique (attention, cette couche sera initialisée aléatoirement, il sera nécessaire de réentraîner le modèle).\n",
        ">\n",
        ">\n",
        ">```python\n",
        ">from transformers import AutoModelForImageClassification\n",
        ">from torchsummary import summary\n",
        ">nb_class: int = 4\n",
        "># Load the model in PyTorch\n",
        ">model = AutoModelForImageClassification.from_pretrained(\"WinKawaks/vit-small-patch16-224\",\n",
        ">                                                          num_labels=nb_class,\n",
        ">                                                  ignore_mismatched_sizes=True)\n",
        ">```\n",
        ">\n",
        "> <div class=\"alert alert-info\"><i class=\"fa fa-info-circle\"></i> &emsp;\n",
        "id2label et label2id sont très utiles dans l'utilisation du modèle dans les pipelines </div>\n",
        ">\n",
        "\n",
        "\n",
        "* Charger notre modèle sous le nom **`model`**.\n",
        "\n",
        "\n",
        "* Afficher le résumé ou la structure du modèle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f9c1f17",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4f9c1f17",
        "outputId": "ed9e1b80-fc72-4e77-f7e8-e1f3d4a106e5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at flaubert/flaubert_base_cased were not used when initializing FlaubertForSequenceClassification: ['pred_layer.proj.bias', 'pred_layer.proj.weight']\n",
            "- This IS expected if you are initializing FlaubertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing FlaubertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of FlaubertForSequenceClassification were not initialized from the model checkpoint at flaubert/flaubert_base_cased and are newly initialized: ['sequence_summary.summary.bias', 'sequence_summary.summary.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "Layer (type:depth-idx)                        Param #\n",
            "======================================================================\n",
            "├─FlaubertModel: 1-1                          --\n",
            "|    └─Embedding: 2-1                         393,216\n",
            "|    └─Embedding: 2-2                         52,783,872\n",
            "|    └─LayerNorm: 2-3                         1,536\n",
            "|    └─ModuleList: 2-4                        --\n",
            "|    |    └─MultiHeadAttention: 3-1           2,362,368\n",
            "|    |    └─MultiHeadAttention: 3-2           2,362,368\n",
            "|    |    └─MultiHeadAttention: 3-3           2,362,368\n",
            "|    |    └─MultiHeadAttention: 3-4           2,362,368\n",
            "|    |    └─MultiHeadAttention: 3-5           2,362,368\n",
            "|    |    └─MultiHeadAttention: 3-6           2,362,368\n",
            "|    |    └─MultiHeadAttention: 3-7           2,362,368\n",
            "|    |    └─MultiHeadAttention: 3-8           2,362,368\n",
            "|    |    └─MultiHeadAttention: 3-9           2,362,368\n",
            "|    |    └─MultiHeadAttention: 3-10          2,362,368\n",
            "|    |    └─MultiHeadAttention: 3-11          2,362,368\n",
            "|    |    └─MultiHeadAttention: 3-12          2,362,368\n",
            "|    └─ModuleList: 2-5                        --\n",
            "|    |    └─LayerNorm: 3-13                   1,536\n",
            "|    |    └─LayerNorm: 3-14                   1,536\n",
            "|    |    └─LayerNorm: 3-15                   1,536\n",
            "|    |    └─LayerNorm: 3-16                   1,536\n",
            "|    |    └─LayerNorm: 3-17                   1,536\n",
            "|    |    └─LayerNorm: 3-18                   1,536\n",
            "|    |    └─LayerNorm: 3-19                   1,536\n",
            "|    |    └─LayerNorm: 3-20                   1,536\n",
            "|    |    └─LayerNorm: 3-21                   1,536\n",
            "|    |    └─LayerNorm: 3-22                   1,536\n",
            "|    |    └─LayerNorm: 3-23                   1,536\n",
            "|    |    └─LayerNorm: 3-24                   1,536\n",
            "|    └─ModuleList: 2-6                        --\n",
            "|    |    └─TransformerFFN: 3-25              4,722,432\n",
            "|    |    └─TransformerFFN: 3-26              4,722,432\n",
            "|    |    └─TransformerFFN: 3-27              4,722,432\n",
            "|    |    └─TransformerFFN: 3-28              4,722,432\n",
            "|    |    └─TransformerFFN: 3-29              4,722,432\n",
            "|    |    └─TransformerFFN: 3-30              4,722,432\n",
            "|    |    └─TransformerFFN: 3-31              4,722,432\n",
            "|    |    └─TransformerFFN: 3-32              4,722,432\n",
            "|    |    └─TransformerFFN: 3-33              4,722,432\n",
            "|    |    └─TransformerFFN: 3-34              4,722,432\n",
            "|    |    └─TransformerFFN: 3-35              4,722,432\n",
            "|    |    └─TransformerFFN: 3-36              4,722,432\n",
            "|    └─ModuleList: 2-7                        --\n",
            "|    |    └─LayerNorm: 3-37                   1,536\n",
            "|    |    └─LayerNorm: 3-38                   1,536\n",
            "|    |    └─LayerNorm: 3-39                   1,536\n",
            "|    |    └─LayerNorm: 3-40                   1,536\n",
            "|    |    └─LayerNorm: 3-41                   1,536\n",
            "|    |    └─LayerNorm: 3-42                   1,536\n",
            "|    |    └─LayerNorm: 3-43                   1,536\n",
            "|    |    └─LayerNorm: 3-44                   1,536\n",
            "|    |    └─LayerNorm: 3-45                   1,536\n",
            "|    |    └─LayerNorm: 3-46                   1,536\n",
            "|    |    └─LayerNorm: 3-47                   1,536\n",
            "|    |    └─LayerNorm: 3-48                   1,536\n",
            "├─SequenceSummary: 1-2                        --\n",
            "|    └─Linear: 2-8                            1,538\n",
            "|    └─Identity: 2-9                          --\n",
            "|    └─Dropout: 2-10                          --\n",
            "|    └─Identity: 2-11                         --\n",
            "======================================================================\n",
            "Total params: 138,234,626\n",
            "Trainable params: 138,234,626\n",
            "Non-trainable params: 0\n",
            "======================================================================\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "FlaubertForSequenceClassification(\n",
              "  (transformer): FlaubertModel(\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (embeddings): Embedding(68729, 768, padding_idx=2)\n",
              "    (layer_norm_emb): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (attentions): ModuleList(\n",
              "      (0-11): 12 x MultiHeadAttention(\n",
              "        (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "    )\n",
              "    (layer_norm1): ModuleList(\n",
              "      (0-11): 12 x LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    )\n",
              "    (ffns): ModuleList(\n",
              "      (0-11): 12 x TransformerFFN(\n",
              "        (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        (act): GELUActivation()\n",
              "      )\n",
              "    )\n",
              "    (layer_norm2): ModuleList(\n",
              "      (0-11): 12 x LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    )\n",
              "  )\n",
              "  (sequence_summary): SequenceSummary(\n",
              "    (summary): Linear(in_features=768, out_features=2, bias=True)\n",
              "    (activation): Identity()\n",
              "    (first_dropout): Dropout(p=0.1, inplace=False)\n",
              "    (last_dropout): Identity()\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "from torchsummary import summary\n",
        "nb_class: int = 2\n",
        "# Load the model in PyTorch\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"flaubert/flaubert_base_cased\",\n",
        "                                                          num_labels=nb_class,\n",
        "                                                          id2label={0:\"negative\", 1:\"positive\"},\n",
        "                                                          label2id={\"negative\":0, \"positive\":1})\n",
        "\n",
        "device: str = \"cuda\"\n",
        "summary(model)\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "890fc781",
      "metadata": {
        "id": "890fc781"
      },
      "source": [
        "* Afficher la sortie de notre modèle pour un batch provenant de **`dataloader_train`**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96f8352c",
      "metadata": {
        "id": "96f8352c",
        "outputId": "378c1023-9674-49a3-98b3-b105895424e9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "SequenceClassifierOutput(loss=tensor(0.7907, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 1.3040,  0.7293],\n",
              "        [-0.2505,  0.4938],\n",
              "        [-0.2077,  0.4371],\n",
              "        [ 0.8450,  0.6191]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_t = next(iter(dataloader_train))\n",
        "model(**X_t)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mkT0aPGzlBel",
      "metadata": {
        "id": "mkT0aPGzlBel"
      },
      "source": [
        "> Il est intéressant de remarquer que le modèle retourne également une fonction de perte dans son forward. Il est possible d'avoir plus d'informations provenant des [étapes de prédiction](https://github.com/huggingface/transformers/blob/e75cb0cb3c5fef887abea6f099252e59a659af9d/src/transformers/models/flaubert/modeling_flaubert.py#L769C9-L769C16) sur le repo Transformers.\n",
        "\n",
        "## Entraînement du modèle\n",
        "\n",
        "> Hugging Face propose une surcouche pour entraîner le modèle sans réécrire les boucles d'entraînement sur PyTorch. Cette méthode est généralement plus simple à implémenter, et sera plus détaillée dans le prochain notebook.\n",
        "\n",
        "* Exécuter la cellule suivante pour définir la fonction d'évaluation du modèle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "R0TFOTVBlBDz",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "R0TFOTVBlBDz",
        "outputId": "cf53a37b-1ebd-40b3-a057-3e1099cd51bd"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'dataloader_test' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn [1], line 33\u001b[0m\n\u001b[0;32m     29\u001b[0m     true_vals \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(true_vals, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_val_avg, accuracy_score(true_vals, predictions\u001b[38;5;241m.\u001b[39margmax(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)) , predictions, true_vals\n\u001b[1;32m---> 33\u001b[0m loss, acc, _, _ \u001b[38;5;241m=\u001b[39m evaluate(\u001b[43mdataloader_test\u001b[49m)\n\u001b[0;32m     35\u001b[0m loss, acc\n",
            "\u001b[1;31mNameError\u001b[0m: name 'dataloader_test' is not defined"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "def evaluate(dataloader_val):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    loss_val_total = 0\n",
        "    predictions, true_vals = [], []\n",
        "\n",
        "    for batch in dataloader_val:\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**batch)\n",
        "\n",
        "        loss = outputs[0]\n",
        "        logits = outputs[1]\n",
        "        loss_val_total += loss.item()\n",
        "\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = batch[\"labels\"].type(torch.LongTensor).cpu().numpy()\n",
        "        predictions.append(logits)\n",
        "        true_vals.append(label_ids)\n",
        "\n",
        "\n",
        "    loss_val_avg = loss_val_total / len(dataloader_val)\n",
        "\n",
        "    predictions = np.concatenate(predictions, axis=0)\n",
        "    true_vals = np.concatenate(true_vals, axis=0)\n",
        "\n",
        "    return loss_val_avg, accuracy_score(true_vals, predictions.argmax(-1)) , predictions, true_vals\n",
        "\n",
        "loss, acc, _, _ = evaluate(dataloader_test)\n",
        "\n",
        "loss, acc"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "51d34ff5",
      "metadata": {
        "id": "51d34ff5"
      },
      "source": [
        "* Définir un optimizer adapté à notre problématique en prenant l'ensemble des paramètres du modèle et un learning rate de 2e-5."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2bad39e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2bad39e",
        "outputId": "588b7aed-ebe4-465f-c017-b0e3a664f687"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\thoma\\.conda\\envs\\doctr\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "epochs = 5\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "\n",
        "# Create a schedule with a learning rate that decreases linearly from the initial lr set in the optimizer to 0, after a warmup period during which it increases linearly from 0 to the initial lr set in the optimizer\n",
        "# scheduler = get_linear_schedule_with_warmup(\n",
        "#     optimizer,\n",
        "#     num_warmup_steps=0,\n",
        "#     num_training_steps=len(dataloader_train) * epochs,\n",
        "# )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f35bd984",
      "metadata": {
        "id": "f35bd984"
      },
      "source": [
        "* Entraîner le modèle sur plusieurs epochs en affichant à chaque epoch la fonction de perte d'entraînement, et les métriques sur test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3-rQTc2Xl3Uf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571,
          "referenced_widgets": [
            "6617b6f0dd9c41b6abde0853967cee19",
            "f0c1415453d94277a65ee66a376473b9",
            "baa7c315fa7c450e9ab16fa057f6ca01",
            "0f2934cee2cc45aab5d0918c6c00ecdd",
            "3421fc0082ab48589d1cf3529061032a",
            "4a49387b5f4f4ce09b17e07e20a58917",
            "0498412644304bb6a338a4fb3fcf9359",
            "84a069fcc0ac4c9e9ca9d5ef1b59e965",
            "75904c617d464aab92a88ec61eb2b8e6",
            "929281def1be4910bb262727d44a0132",
            "f6f305ee286b4787af803f27aecd8419",
            "230ab0ef44b948e6b129fc246fc8ae90",
            "3ffc755e43494b1497bf2c4b5777aa6a",
            "ccc6407074424cd781209485295bbcac",
            "25a7bcd91b24459d8d3b163933a1ac83",
            "5ded6500a7eb4df0bc8ff50604f833f5",
            "30158eef9c824683b3ffd26dce017a98",
            "6b43777a7f3f46d7b3581954a7e7314f",
            "6dd68ef0847044718b2ccbdc8134cef2",
            "23589ae7dc5f4dc0ad099077abe962ec",
            "9ba2eb82fa3e4e92b11ec895b1a1b591",
            "2b96fd9664cc45b08a370c7384004a65",
            "6e816201d43741be9bae5a4939c6c296",
            "2ac58a7b04bb43c29bf102bbed60cfaf",
            "8b1c76716ed54f33a0fcdf79b5b5094d",
            "7d0893cfad944a49b7dba0001f4af8cb",
            "65dfe068ca78483688236536501947e7",
            "b2af55fc3d2d49b79958dfa756d2a169",
            "2f914794ff2c49b3a168fa3da41e5725",
            "61deef95591e452f86e54cd6aabdcb84",
            "3c8d10b6f222404fa9a0687bdb4fa9d1",
            "05dc29a3ca3b45f7b7681e06efe2df49",
            "1001a5f5f0424cf0bf83f861113a5246",
            "f2b3090f81964e55accea780c2ac0cf9",
            "e8958d8c2fc646f49af86e9e2d992694",
            "9688c5da0beb4f168951cde7528d0066",
            "5444c06753714fb7a5c5901f3ac9da70",
            "e3c220ed249944898e214ecafa9a4d04",
            "ef06f2bb3df449efb3661da63096c0bc",
            "26f3ab65f0d54716b6bb11a25c7b3119",
            "ead99bf0ac014f7bb68f0f4ef3395089",
            "c6f89af0c64f4908a33bdc8262e862cc",
            "1baf1c4c8c8c4cd09cecdd2f0ebbe484",
            "879c6678fdaa463f90bb67ca28159136",
            "dbd2ef1830e6411c903de897e079e7da",
            "f0f0907218d341bb9e64275741eefb87",
            "0e99d54684244856ba4a17694ee30134",
            "16f77c89e6e3497c909d317253276e2c",
            "7c3ef7703e454c1fb08d11f06ce50d09",
            "e7dccc714c144f57be72ee7066a79fa6",
            "645ba00d42c242d9a97e22162791a751",
            "af2d789ba3274b708ba7fa682df3618a",
            "ab46ca57b7664aef8ff7100148dabe94",
            "1a99e4f93c8d46e098f907a3e2dc5fb0",
            "217558f232e7482da7b98da597c8c9ea",
            "d0b755b708af4266bac494902df8c491",
            "62daba2138424245a4d17b392b07cec7",
            "d4ba239943854f49bed68b321c218d38",
            "d7f737acb5ff481d91a4740e3cf184be",
            "217aa8428454430dbd13d9fea9f2f85a",
            "601c0b1d79d14cd49bd89e30e61e5dfe",
            "76a848d84b3b4c4da6dfda4d21d45212",
            "04d32f230b4748bf811d0064d79b728c",
            "b5161a33f32c466cbfb0fea6219dba20",
            "325531e6d19d4c49bda0f6cfdc82ed3a",
            "e4c4a70ddc7d4c05a5cd2c274698327b",
            "8d9c19b441cc4681a74a10247757171d",
            "3d456c70b40046d09d00dddd7ba59706",
            "183d3b8be4d74e6280ad37747e09289a",
            "4eea4f4983bd49b4af526686193315b6",
            "44d70fbc2fdb412fb137a929c4628dcc",
            "b2e4ab6eb5d24327a02fc2f17df27111",
            "e7e60724fabf4ccfb8086934a5719af3",
            "3456751f0f794469b6cc8d0da26724cc"
          ]
        },
        "id": "3-rQTc2Xl3Uf",
        "outputId": "c9e5722a-59ea-4d4b-d23a-2b182f896b34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finetuning in progres ...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d0b755b708af4266bac494902df8c491",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "############################## epoch : 1 ##############################\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "62daba2138424245a4d17b392b07cec7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 1:   0%|          | 0/200 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss Train :  0.7177325626183301\n",
            "Loss Test :  0.5738329946063458\n",
            "ACC Test :  0.8\n",
            "############################## epoch : 2 ##############################\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d4ba239943854f49bed68b321c218d38",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 2:   0%|          | 0/200 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss Train :  0.6929078461701283\n",
            "Loss Test :  0.5730371774593368\n",
            "ACC Test :  0.83\n",
            "############################## epoch : 3 ##############################\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d7f737acb5ff481d91a4740e3cf184be",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 3:   0%|          | 0/200 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss Train :  0.6241576630817144\n",
            "Loss Test :  0.378971343729645\n",
            "ACC Test :  0.85\n",
            "############################## epoch : 4 ##############################\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "217aa8428454430dbd13d9fea9f2f85a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 4:   0%|          | 0/200 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss Train :  0.47505286275118125\n",
            "Loss Test :  0.5406244295567739\n",
            "ACC Test :  0.855\n",
            "############################## epoch : 5 ##############################\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "601c0b1d79d14cd49bd89e30e61e5dfe",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 5:   0%|          | 0/200 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss Train :  0.3842799337579345\n",
            "Loss Test :  0.7660978005558718\n",
            "ACC Test :  0.865\n",
            "############################## epoch : 6 ##############################\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "76a848d84b3b4c4da6dfda4d21d45212",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 6:   0%|          | 0/200 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss Train :  0.40087147970356457\n",
            "Loss Test :  0.7662591949570924\n",
            "ACC Test :  0.86\n",
            "############################## epoch : 7 ##############################\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "04d32f230b4748bf811d0064d79b728c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 7:   0%|          | 0/200 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss Train :  0.2231565921073343\n",
            "Loss Test :  1.0518571807528496\n",
            "ACC Test :  0.825\n",
            "############################## epoch : 8 ##############################\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b5161a33f32c466cbfb0fea6219dba20",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 8:   0%|          | 0/200 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss Train :  0.16284864539855334\n",
            "Loss Test :  1.212808700165042\n",
            "ACC Test :  0.81\n",
            "############################## epoch : 9 ##############################\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "325531e6d19d4c49bda0f6cfdc82ed3a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 9:   0%|          | 0/200 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss Train :  0.13114522237616255\n",
            "Loss Test :  1.2008075063619617\n",
            "ACC Test :  0.85\n",
            "############################## epoch : 10 ##############################\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e4c4a70ddc7d4c05a5cd2c274698327b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 10:   0%|          | 0/200 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss Train :  0.11240040973595342\n",
            "Loss Test :  1.8322077968191888\n",
            "ACC Test :  0.77\n",
            "############################## epoch : 11 ##############################\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8d9c19b441cc4681a74a10247757171d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 11:   0%|          | 0/200 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss Train :  0.13873892806943103\n",
            "Loss Test :  1.1045943044534943\n",
            "ACC Test :  0.855\n",
            "############################## epoch : 12 ##############################\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3d456c70b40046d09d00dddd7ba59706",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 12:   0%|          | 0/200 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss Train :  0.06698750054057456\n",
            "Loss Test :  1.2575880491642601\n",
            "ACC Test :  0.86\n",
            "############################## epoch : 13 ##############################\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "183d3b8be4d74e6280ad37747e09289a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 13:   0%|          | 0/200 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss Train :  0.012158121406133376\n",
            "Loss Test :  1.3716800666574271\n",
            "ACC Test :  0.87\n",
            "############################## epoch : 14 ##############################\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4eea4f4983bd49b4af526686193315b6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 14:   0%|          | 0/200 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss Train :  0.032357053706060554\n",
            "Loss Test :  1.5260234594866358\n",
            "ACC Test :  0.85\n",
            "############################## epoch : 15 ##############################\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "44d70fbc2fdb412fb137a929c4628dcc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 15:   0%|          | 0/200 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss Train :  0.0706527520367095\n",
            "Loss Test :  1.2307018628040352\n",
            "ACC Test :  0.85\n",
            "############################## epoch : 16 ##############################\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b2e4ab6eb5d24327a02fc2f17df27111",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 16:   0%|          | 0/200 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss Train :  0.047565446242475676\n",
            "Loss Test :  1.2819190181411795\n",
            "ACC Test :  0.86\n",
            "############################## epoch : 17 ##############################\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e7e60724fabf4ccfb8086934a5719af3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 17:   0%|          | 0/200 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss Train :  0.06448496040061912\n",
            "Loss Test :  1.569544727769553\n",
            "ACC Test :  0.845\n",
            "############################## epoch : 18 ##############################\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3456751f0f794469b6cc8d0da26724cc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 18:   0%|          | 0/200 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn [13], line 39\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Backpropagtion\u001b[39;00m\n\u001b[0;32m     37\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m---> 39\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclip_grad_norm_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# On actualise les parametrer grace a l'optimizer\u001b[39;00m\n\u001b[0;32m     42\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
            "File \u001b[1;32m~\\.conda\\envs\\doctr\\lib\\site-packages\\torch\\nn\\utils\\clip_grad.py:76\u001b[0m, in \u001b[0;36mclip_grad_norm_\u001b[1;34m(parameters, max_norm, norm_type, error_if_nonfinite, foreach)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ((device, _), [grads]) \u001b[38;5;129;01min\u001b[39;00m grouped_grads\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (foreach \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m foreach) \u001b[38;5;129;01mand\u001b[39;00m _has_foreach_support(grads, device\u001b[38;5;241m=\u001b[39mdevice):\n\u001b[1;32m---> 76\u001b[0m         \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_foreach_mul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclip_coef_clamped\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m foreach:\n\u001b[0;32m     78\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mforeach=True was passed, but can\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mt use the foreach API on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice\u001b[38;5;241m.\u001b[39mtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m tensors\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from tqdm.notebook import tqdm\n",
        "\n",
        "print(\"Finetuning in progres ...\")\n",
        "\n",
        "for epoch in tqdm(range(1, 100 + 1)):\n",
        "\n",
        "    print(\n",
        "        \"############################## epoch : {} ##############################\".format(\n",
        "            epoch\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # On met le modele en mode 'training'\n",
        "    # Dans ce mode certaines couches du modele agissent differement\n",
        "    model.train()\n",
        "\n",
        "    # On initialise la loss pour cette epoque\n",
        "    loss_train_total = 0\n",
        "\n",
        "    # Pour chaque batch\n",
        "    progress_bar = tqdm(\n",
        "        dataloader_train, desc=\"Epoch {:1d}\".format(epoch), leave=False, disable=False\n",
        "    )\n",
        "\n",
        "    for batch in progress_bar:\n",
        "        # On met le gradient a 0\n",
        "        model.zero_grad()\n",
        "\n",
        "        # On passe la donnee au model et on recupere la loss\n",
        "        outputs = model(**batch)\n",
        "\n",
        "        loss = outputs[0]\n",
        "        # On incremente la loss totale\n",
        "        # .item() donne la valeur numerique de la loss\n",
        "        loss_train_total += loss.item()\n",
        "        # Backpropagtion\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # On actualise les parametrer grace a l'optimizer\n",
        "        optimizer.step()\n",
        "        # scheduler.step()\n",
        "\n",
        "        progress_bar.set_postfix(\n",
        "            {\"training_loss\": \"{:.3f}\".format(loss.item() / len(batch))}\n",
        "        )\n",
        "    print(\"Loss Train : \", loss_train_total/len(dataloader_train))\n",
        "    loss_test, acc_test, _, _ = evaluate(dataloader_test)\n",
        "    print(\"Loss Test : \", loss_test)\n",
        "    print(\"ACC Test : \", acc_test)\n",
        "\n",
        "\n",
        "print(\"Finetuning done!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f59328b",
      "metadata": {
        "id": "9f59328b"
      },
      "source": [
        "> Une fois le modèle est entraîné, il peut être intéressant de le sauvegarder.\n",
        ">\n",
        ">```python\n",
        "># Save the model\n",
        ">model.save_pretrained('my_finetuned_model')\n",
        "># Load a local model\n",
        ">model = AutoModelForSequenceClassification.from_pretrained('my_finetuned_model')\n",
        ">```\n",
        ">\n",
        "> Il est également possible de le réutiliser dans un pipeline pour éviter de refaire les étapes de post-traitement.\n",
        ">\n",
        ">```python\n",
        ">from transformers import pipeline\n",
        ">nlp = pipeline(\"text-classification\", model=model, tokenizer=tokenizer, device=0)\n",
        ">```\n",
        "\n",
        "* A l'aide d'un pipeline, prédire si la phrase suivante est positive ou négative \"Réactivité lors de renégociation, contact facile...\"\n",
        "\n",
        "\n",
        "* Pareil pour \"Très cher, couverture mediocre compte tenu cotisation mensuelle.\\nNe donne pas du tout l'impression que vous êtes un client mais plutôt un tiroir caisse.\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "939cb856",
      "metadata": {
        "id": "939cb856",
        "outputId": "d81e2fd1-8f72-45a7-dc66-6adbd216dbd1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'label': 'negative', 'score': 0.9967676401138306}]"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "nlp = pipeline(\"text-classification\", model=model, tokenizer=tokenizer, device=0)\n",
        "nlp(\"Réactivité lors de renégociation, contact facile...\")\n",
        "nlp(\"Très cher, couverture mediocre compte tenu cotisation mensuelle.\\nNe donne pas du tout l'impression que vous êtes un client mais plutôt un tiroir caisse.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "012ff01d",
      "metadata": {
        "id": "012ff01d"
      },
      "source": [
        "<hr style=\"border-width:2px;border-color:#75DFC1\">\n",
        "<h2 style = \"text-align:center\" > Ce qu'il faut retenir </h2>\n",
        "<hr style=\"border-width:2px;border-color:#75DFC1\">\n",
        "\n",
        "## Transformers\n",
        "\n",
        "> Selon l'utilisation, il n'est pas toujours nécessaire d'utiliser un encodeur ou un décodeur d'un transformer. En effet, un simple encodeur avec une tête adaptée peut être suffisant. Alors que dans des tâches qui nécessitent une génération, il sera nécessaire d'avoir au moins un décodeur.\n",
        ">\n",
        ">\n",
        "> Le critère de temps de calcul peut également être important selon les problématiques et peut pousser vers des structures comme le DistilBERT, DynaBERT, AlBERT (A Lite BERT)...\n",
        ">\n",
        ">\n",
        "> Les modèles Transformers sont très intéressants par leur propriété de transfert learning importante. Sans cette première étape de pré-entraînement, ils dépassent difficilement les approches plus traditionnelles. Vous pourrez sélectionner votre modèle en fonction des benchmarks et leaderboards que l'on peut retrouver:\n",
        ">\n",
        "> * [GLUE](https://gluebenchmark.com/leaderboard) pour des tâches de classification/NER... en anglais\n",
        ">\n",
        ">\n",
        "> * [FLUE](http://fluebenchmark.com/) pour des tâches de classification/NER... en français\n",
        ">\n",
        ">\n",
        "> * Leaderboard pour du text embedding: https://huggingface.co/spaces/mteb/leaderboard\n",
        ">\n",
        ">\n",
        "> * Leaderboard pour des LLMs: https://huggingface.co/spaces/lmarena-ai/chatbot-arena-leaderboard\n",
        "\n",
        "\n",
        "## Préparation des données\n",
        "\n",
        "> La préparation sur Hugging Face se fait généralement avec des datasets personnalisés :\n",
        ">\n",
        "> ```python\n",
        ">import torch\n",
        ">from PIL import Image\n",
        ">from transformers import AutoImageProcessor\n",
        ">from torch.utils.data import DataLoader\n",
        ">\n",
        ">processor = AutoImageProcessor.from_pretrained(\"WinKawaks/vit-small-patch16-224\")\n",
        ">\n",
        ">class NewsGroupsDataset(torch.utils.data.Dataset):\n",
        ">     def __init__(self, X, y, device='cuda'):\n",
        ">         self.device = device\n",
        ">         self.X = X\n",
        ">         self.y = y\n",
        ">\n",
        ">     def __getitem__(self, idx):\n",
        ">         \n",
        ">         im = Image.open(self.X[idx])\n",
        ">\n",
        ">         encoding = processor(im, return_tensors=\"pt\")\n",
        ">\n",
        ">         return {\"pixel_values\" : encoding[\"pixel_values\"][0],\n",
        ">                 \"labels\" : torch.tensor(self.y[idx])}\n",
        ">\n",
        ">     def __len__(self):\n",
        ">         return len(self.X)\n",
        ">\n",
        ">device = 'cuda'\n",
        ">\n",
        ">dataset_train = NewsGroupsDataset(X_train, y_train, device)\n",
        ">dataloader_train = DataLoader(dataset_train, batch_size=8, shuffle=True)\n",
        ">\n",
        ">dataset_test = NewsGroupsDataset(X_test, y_test, device)\n",
        ">dataloader_test = DataLoader(dataset_test, batch_size=8, shuffle=True)\n",
        ">```\n",
        "\n",
        "\n",
        "## Entraînement du modèle avec une boucle personnalisée\n",
        "\n",
        "> Il est possible d'entraîner le modèle avec une boucle personnalisée en PyTorch très similaire à ce qui a été présenté dans les derniers modules.\n",
        ">\n",
        ">```python\n",
        ">from tqdm.notebook import tqdm\n",
        ">\n",
        ">for epoch in tqdm(range(1, epochs + 1)):\n",
        ">     model.train()\n",
        ">\n",
        ">     # On initialise la loss pour cette epoque\n",
        ">     loss_train_total = 0\n",
        ">\n",
        ">     # Pour chaque batch\n",
        ">     progress_bar = tqdm(\n",
        ">         dataloader_train, desc=\"Epoch {:1d}\".format(epoch), leave=False, disable=False\n",
        ">     )\n",
        ">\n",
        ">     for batch in progress_bar:\n",
        ">         # On met le gradient a 0\n",
        ">         model.zero_grad()\n",
        ">\n",
        ">         # On passe la donnee au model et on recupere la loss\n",
        ">         outputs = model(**batch)\n",
        ">\n",
        ">         loss = outputs[0]\n",
        ">         # On incremente la loss totale\n",
        ">         loss_train_total += loss.item()\n",
        ">         # Backpropagtion\n",
        ">         loss.backward()\n",
        ">\n",
        ">         torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        ">\n",
        ">         # On actualise les paramètres grâce a l'optimizer\n",
        ">         optimizer.step()\n",
        ">\n",
        ">         progress_bar.set_postfix(\n",
        ">             {\"training_loss\": \"{:.3f}\".format(loss.item() / len(batch))}\n",
        ">         )\n",
        ">     print(\"Loss Train : \", loss_train_total/len(dataloader_train))\n",
        ">     loss_test, acc_test, _, _ = evaluate(dataloader_test)\n",
        ">     print(\"Loss Test : \", loss_test)\n",
        ">     print(\"ACC Test : \", acc_test)\n",
        ">```\n",
        ">\n",
        "\n",
        "## Entraînement du modèle avec Trainer\n",
        "\n",
        "> Hugging Face propose également une sur-couche pour entraîner le modèle sans réécrire les boucles d'entraînement.\n",
        ">\n",
        ">### 1. Définir les arguments d'entraînement : TrainingArguments\n",
        ">\n",
        "> Pour cela, il est avant tout nécessaire de définir les arguments importants utilisés lors lors de l'entraînement avec la fonction `TrainingArguments` ([plus d'information](https://huggingface.co/docs/transformers/v4.39.3/en/main_classes/trainer#transformers.TrainingArguments)).\n",
        ">\n",
        ">\n",
        ">```python\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',          # chemin de stockage des poids du modèle\n",
        "    num_train_epochs=1,              # nombre d'époques pour l'entraînement\n",
        "    per_device_train_batch_size=8,   # batch size pour l'entraînement\n",
        "    per_device_eval_batch_size=20,   # batch size pour l'évaluation du modèle\n",
        "    learning_rate=1e-4,              # taux d'apprentissage\n",
        "    weight_decay=0.01,               # paramètre décidant des poids\n",
        "    logging_dir='./logs',            # chemin de stockage des logs\n",
        "    load_best_model_at_end=True,     # utilisation du meilleur modèle à l'issue de l'entraînement\n",
        "    logging_steps=400,               # log & enregistrer les poids à chaque 400 itérations\n",
        "    save_steps=400,\n",
        "    evaluation_strategy=\"epoch\",     # évaluation à chaque epoch\n",
        ")\n",
        ">```\n",
        "> Plus d'information au travers de ce [lien](https://huggingface.co/docs/transformers/v4.39.3/en/main_classes/trainer#transformers.TrainingArguments).\n",
        ">\n",
        ">\n",
        "> ### 2. Définir les métriques\n",
        ">\n",
        ">```python\n",
        ">import evaluate\n",
        ">metric = evaluate.load(\"accuracy\")\n",
        ">def compute_metrics(eval_pred):\n",
        ">     logits, labels = eval_pred\n",
        ">     predictions = np.argmax(logits, axis=-1)\n",
        ">     return metric.compute(predictions=predictions, references=labels)\n",
        ">```\n",
        ">\n",
        "> Le lien suivant vous donne la liste de métrique disponible dans le package `evaluate` : https://huggingface.co/metrics\n",
        ">\n",
        ">  ### 3. Entraîner le modèle\n",
        ">\n",
        "> Une fois la création du training_args et des métriques, la fonction `Trainer` de **`transformers`** prendra tous les éléments nécessaires dans le but d'entraîner le modèle :\n",
        ">\n",
        ">```python\n",
        ">trainer = Trainer(\n",
        ">    model=model,\n",
        ">    args=training_args,\n",
        ">    train_dataset=dataset_train,\n",
        ">    eval_dataset=dataset_test,\n",
        ">    compute_metrics=compute_metrics,\n",
        ">)\n",
        ">```\n",
        ">\n",
        "> La méthode `train` permettra ensuite d'entraîner le modèle.\n",
        ">\n",
        ">```python\n",
        ">trainer.train()\n",
        ">```"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python (doctr)",
      "language": "python",
      "name": "doctr"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0498412644304bb6a338a4fb3fcf9359": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "05dc29a3ca3b45f7b7681e06efe2df49": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e99d54684244856ba4a17694ee30134": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af2d789ba3274b708ba7fa682df3618a",
            "max": 3133,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ab46ca57b7664aef8ff7100148dabe94",
            "value": 1815
          }
        },
        "0f2934cee2cc45aab5d0918c6c00ecdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_929281def1be4910bb262727d44a0132",
            "placeholder": "​",
            "style": "IPY_MODEL_f6f305ee286b4787af803f27aecd8419",
            "value": " 3/5 [2:16:47&lt;1:17:20, 2320.43s/it]"
          }
        },
        "1001a5f5f0424cf0bf83f861113a5246": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "16f77c89e6e3497c909d317253276e2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a99e4f93c8d46e098f907a3e2dc5fb0",
            "placeholder": "​",
            "style": "IPY_MODEL_217558f232e7482da7b98da597c8c9ea",
            "value": " 1815/3133 [20:46&lt;14:59,  1.47it/s, training_loss=0.538]"
          }
        },
        "1a99e4f93c8d46e098f907a3e2dc5fb0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1baf1c4c8c8c4cd09cecdd2f0ebbe484": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "217558f232e7482da7b98da597c8c9ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "230ab0ef44b948e6b129fc246fc8ae90": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3ffc755e43494b1497bf2c4b5777aa6a",
              "IPY_MODEL_ccc6407074424cd781209485295bbcac",
              "IPY_MODEL_25a7bcd91b24459d8d3b163933a1ac83"
            ],
            "layout": "IPY_MODEL_5ded6500a7eb4df0bc8ff50604f833f5"
          }
        },
        "23589ae7dc5f4dc0ad099077abe962ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "25a7bcd91b24459d8d3b163933a1ac83": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ba2eb82fa3e4e92b11ec895b1a1b591",
            "placeholder": "​",
            "style": "IPY_MODEL_2b96fd9664cc45b08a370c7384004a65",
            "value": " 3133/3133 [35:50&lt;00:00,  1.50it/s, training_loss=0.528]"
          }
        },
        "26f3ab65f0d54716b6bb11a25c7b3119": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2ac58a7b04bb43c29bf102bbed60cfaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b2af55fc3d2d49b79958dfa756d2a169",
            "placeholder": "​",
            "style": "IPY_MODEL_2f914794ff2c49b3a168fa3da41e5725",
            "value": "Epoch 2: 100%"
          }
        },
        "2b96fd9664cc45b08a370c7384004a65": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2f914794ff2c49b3a168fa3da41e5725": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "30158eef9c824683b3ffd26dce017a98": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3421fc0082ab48589d1cf3529061032a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c8d10b6f222404fa9a0687bdb4fa9d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3ffc755e43494b1497bf2c4b5777aa6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_30158eef9c824683b3ffd26dce017a98",
            "placeholder": "​",
            "style": "IPY_MODEL_6b43777a7f3f46d7b3581954a7e7314f",
            "value": "Epoch 1: 100%"
          }
        },
        "4a49387b5f4f4ce09b17e07e20a58917": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5444c06753714fb7a5c5901f3ac9da70": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1baf1c4c8c8c4cd09cecdd2f0ebbe484",
            "placeholder": "​",
            "style": "IPY_MODEL_879c6678fdaa463f90bb67ca28159136",
            "value": " 3133/3133 [35:50&lt;00:00,  1.49it/s, training_loss=0.462]"
          }
        },
        "5ded6500a7eb4df0bc8ff50604f833f5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "61deef95591e452f86e54cd6aabdcb84": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "645ba00d42c242d9a97e22162791a751": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "65dfe068ca78483688236536501947e7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "6617b6f0dd9c41b6abde0853967cee19": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f0c1415453d94277a65ee66a376473b9",
              "IPY_MODEL_baa7c315fa7c450e9ab16fa057f6ca01",
              "IPY_MODEL_0f2934cee2cc45aab5d0918c6c00ecdd"
            ],
            "layout": "IPY_MODEL_3421fc0082ab48589d1cf3529061032a"
          }
        },
        "6b43777a7f3f46d7b3581954a7e7314f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6dd68ef0847044718b2ccbdc8134cef2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e816201d43741be9bae5a4939c6c296": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2ac58a7b04bb43c29bf102bbed60cfaf",
              "IPY_MODEL_8b1c76716ed54f33a0fcdf79b5b5094d",
              "IPY_MODEL_7d0893cfad944a49b7dba0001f4af8cb"
            ],
            "layout": "IPY_MODEL_65dfe068ca78483688236536501947e7"
          }
        },
        "75904c617d464aab92a88ec61eb2b8e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7c3ef7703e454c1fb08d11f06ce50d09": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d0893cfad944a49b7dba0001f4af8cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05dc29a3ca3b45f7b7681e06efe2df49",
            "placeholder": "​",
            "style": "IPY_MODEL_1001a5f5f0424cf0bf83f861113a5246",
            "value": " 3133/3133 [35:47&lt;00:00,  1.49it/s, training_loss=0.526]"
          }
        },
        "84a069fcc0ac4c9e9ca9d5ef1b59e965": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "879c6678fdaa463f90bb67ca28159136": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8b1c76716ed54f33a0fcdf79b5b5094d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_61deef95591e452f86e54cd6aabdcb84",
            "max": 3133,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3c8d10b6f222404fa9a0687bdb4fa9d1",
            "value": 3133
          }
        },
        "929281def1be4910bb262727d44a0132": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9688c5da0beb4f168951cde7528d0066": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ead99bf0ac014f7bb68f0f4ef3395089",
            "max": 3133,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c6f89af0c64f4908a33bdc8262e862cc",
            "value": 3133
          }
        },
        "9ba2eb82fa3e4e92b11ec895b1a1b591": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab46ca57b7664aef8ff7100148dabe94": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "af2d789ba3274b708ba7fa682df3618a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2af55fc3d2d49b79958dfa756d2a169": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "baa7c315fa7c450e9ab16fa057f6ca01": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84a069fcc0ac4c9e9ca9d5ef1b59e965",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_75904c617d464aab92a88ec61eb2b8e6",
            "value": 3
          }
        },
        "c6f89af0c64f4908a33bdc8262e862cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ccc6407074424cd781209485295bbcac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6dd68ef0847044718b2ccbdc8134cef2",
            "max": 3133,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_23589ae7dc5f4dc0ad099077abe962ec",
            "value": 3133
          }
        },
        "dbd2ef1830e6411c903de897e079e7da": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f0f0907218d341bb9e64275741eefb87",
              "IPY_MODEL_0e99d54684244856ba4a17694ee30134",
              "IPY_MODEL_16f77c89e6e3497c909d317253276e2c"
            ],
            "layout": "IPY_MODEL_7c3ef7703e454c1fb08d11f06ce50d09"
          }
        },
        "e3c220ed249944898e214ecafa9a4d04": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "e7dccc714c144f57be72ee7066a79fa6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8958d8c2fc646f49af86e9e2d992694": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef06f2bb3df449efb3661da63096c0bc",
            "placeholder": "​",
            "style": "IPY_MODEL_26f3ab65f0d54716b6bb11a25c7b3119",
            "value": "Epoch 3: 100%"
          }
        },
        "ead99bf0ac014f7bb68f0f4ef3395089": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef06f2bb3df449efb3661da63096c0bc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0c1415453d94277a65ee66a376473b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a49387b5f4f4ce09b17e07e20a58917",
            "placeholder": "​",
            "style": "IPY_MODEL_0498412644304bb6a338a4fb3fcf9359",
            "value": " 60%"
          }
        },
        "f0f0907218d341bb9e64275741eefb87": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7dccc714c144f57be72ee7066a79fa6",
            "placeholder": "​",
            "style": "IPY_MODEL_645ba00d42c242d9a97e22162791a751",
            "value": "Epoch 4:  58%"
          }
        },
        "f2b3090f81964e55accea780c2ac0cf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e8958d8c2fc646f49af86e9e2d992694",
              "IPY_MODEL_9688c5da0beb4f168951cde7528d0066",
              "IPY_MODEL_5444c06753714fb7a5c5901f3ac9da70"
            ],
            "layout": "IPY_MODEL_e3c220ed249944898e214ecafa9a4d04"
          }
        },
        "f6f305ee286b4787af803f27aecd8419": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}